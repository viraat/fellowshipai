{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fellowship AI challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge goals\n",
    "1. Problem solving ability - did you understand the problem correctly, and did you take logical steps to solve it?  \n",
    "2. Machine learning skills - what sort of models did you use? How rigorous was your exploratory analysis of the data, your choice and fine tuning of models, and your assessment of results.  \n",
    "3. Communication skills - is your solution readable and well explained? Messiness and raw code with no explanation does not reflect well on your potential for working well with our business partners during the fellowship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistakes to avoid\n",
    "\n",
    "- Skipping exploratory analysis and feature engineering  \n",
    "Do not jump straight into fitting models without demonstrating to us, in your Jupyter notebook, that you have understood and thought about the dataset.\n",
    "\n",
    "- Choosing models with no explanation  \n",
    "Please use the notebook to explain your thought process. We care about this as much as we care about your results.\n",
    "\n",
    "- Unreadable notebooks  \n",
    "Make sure to run your notebook before sharing so that we can see the results. We won't be running your code on our machines. On the flip side, please do not print out the entire dataset or endless rounds of epochs.\n",
    "\n",
    "- Overly simplistic final results  \n",
    "Your final results should consist of more than a single number or percentage printout. Explain why you chose the success metrics you chose, and analyze what your output means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions to Consider\n",
    "Ask yourself why would they have selected this problem for the challenge? What are some gotchas in this domain I should know about?  \n",
    "What is the highest level of accuracy that others have achieved with this dataset or similar problems / datasets ?  \n",
    "What types of visualizations will help me grasp the nature of the problem / data?  \n",
    "What feature engineering might help improve the signal?  \n",
    "Which modeling techniques are good at capturing the types of relationships I see in this data?  \n",
    "Now that I have a model, how can I be sure that I didn't introduce a bug in the code? If results are too good to be true, they probably are!  \n",
    "What are some of the weaknesses of the model and and how can the model be improved with additional work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand OmniGlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources \n",
    "Omniglot paper - http://science.sciencemag.org/content/sci/350/6266/1332.full.pdf  \n",
    "Keras - https://sorenbouma.github.io/blog/oneshot/  \n",
    "CS231n - http://cs231n.stanford.edu/reports/2017/pdfs/131.pdf  \n",
    "Siamese nets paper - http://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "omniglot_trainset = datasets.Omniglot(root='./omniglot_data/', download=True, background=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "omniglot_evalset = datasets.Omniglot(root='./omniglot_data/', download=True, background=False, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic stats about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19280, 13180)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(omniglot_trainset), len(omniglot_evalset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 964)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(omniglot_trainset._alphabets), len(omniglot_trainset._characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gujarati',\n",
       " 'Korean',\n",
       " 'Arcadian',\n",
       " 'Malay_(Jawi_-_Arabic)',\n",
       " 'Grantha',\n",
       " 'Blackfoot_(Canadian_Aboriginal_Syllabics)',\n",
       " 'Balinese',\n",
       " 'Futurama',\n",
       " 'N_Ko',\n",
       " 'Burmese_(Myanmar)',\n",
       " 'Anglo-Saxon_Futhorc',\n",
       " 'Mkhedruli_(Georgian)',\n",
       " 'Latin',\n",
       " 'Braille',\n",
       " 'Sanskrit',\n",
       " 'Japanese_(hiragana)',\n",
       " 'Tagalog',\n",
       " 'Greek',\n",
       " 'Ojibwe_(Canadian_Aboriginal_Syllabics)',\n",
       " 'Japanese_(katakana)',\n",
       " 'Early_Aramaic',\n",
       " 'Hebrew',\n",
       " 'Tifinagh',\n",
       " 'Asomtavruli_(Georgian)',\n",
       " 'Armenian',\n",
       " 'Syriac_(Estrangelo)',\n",
       " 'Alphabet_of_the_Magi',\n",
       " 'Cyrillic',\n",
       " 'Bengali',\n",
       " 'Inuktitut_(Canadian_Aboriginal_Syllabics)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omniglot_trainset._alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "per_language_count = dict()\n",
    "for a in omniglot_trainset._alphabets:\n",
    "    per_language_count['{}'.format(a)] = len(os.listdir(os.path.join(omniglot_trainset.target_folder, a)))\n",
    "plt.bar(range(len(per_language_count)), list(per_language_count.values()))\n",
    "# plt.xticks(range(len(per_language_count)), list(per_language_count.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 659)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(omniglot_evalset._alphabets), len(omniglot_evalset._characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oriya',\n",
       " 'ULOG',\n",
       " 'Tengwar',\n",
       " 'Malayalam',\n",
       " 'Atlantean',\n",
       " 'Keble',\n",
       " 'Manipuri',\n",
       " 'Gurmukhi',\n",
       " 'Tibetan',\n",
       " 'Aurek-Besh',\n",
       " 'Ge_ez',\n",
       " 'Angelic',\n",
       " 'Old_Church_Slavonic_(Cyrillic)',\n",
       " 'Kannada',\n",
       " 'Avesta',\n",
       " 'Mongolian',\n",
       " 'Syriac_(Serto)',\n",
       " 'Atemayar_Qelisayer',\n",
       " 'Sylheti',\n",
       " 'Glagolitic']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omniglot_evalset._alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_per_lang_count = dict()\n",
    "for a in omniglot_evalset._alphabets:\n",
    "    eval_per_lang_count['{}'.format(a)] = len(os.listdir(os.path.join(omniglot_evalset.target_folder, a)))\n",
    "plt.bar(range(len(eval_per_lang_count)), list(eval_per_lang_count.values()))\n",
    "# plt.xticks(range(len(eval_per_lang_count)), list(eval_per_lang_count.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: Futurama/character09, img shape: (105, 105)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = np.random.randint(len(omniglot_trainset))\n",
    "img, target = omniglot_trainset[ind]\n",
    "class_name = omniglot_trainset._characters[target]\n",
    "plt.imshow(np.asarray(img), cmap='gray')\n",
    "print('class: {}, img shape: {}'.format(class_name, img.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: Malayalam/character31, img shape: (105, 105)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = np.random.randint(len(omniglot_evalset))\n",
    "img, target = omniglot_evalset[ind]\n",
    "class_name = omniglot_evalset._characters[target]\n",
    "plt.imshow(np.asarray(img), cmap='gray')\n",
    "print('class: {}, img shape: {}'.format(class_name, img.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - nearest neighbour from raw pixel values on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_image(img, size=(32, 32)):\n",
    "    flat = cv2.resize(img, size).flatten()\n",
    "    return cv2.normalize(flat, flat, norm_type=cv2.NORM_MINMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_image(np.asarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 1000/19280\n",
      "[INFO] processed 2000/19280\n",
      "[INFO] processed 3000/19280\n",
      "[INFO] processed 4000/19280\n",
      "[INFO] processed 5000/19280\n",
      "[INFO] processed 6000/19280\n",
      "[INFO] processed 7000/19280\n",
      "[INFO] processed 8000/19280\n",
      "[INFO] processed 9000/19280\n",
      "[INFO] processed 10000/19280\n",
      "[INFO] processed 11000/19280\n",
      "[INFO] processed 12000/19280\n",
      "[INFO] processed 13000/19280\n",
      "[INFO] processed 14000/19280\n",
      "[INFO] processed 15000/19280\n",
      "[INFO] processed 16000/19280\n",
      "[INFO] processed 17000/19280\n",
      "[INFO] processed 18000/19280\n",
      "[INFO] processed 19000/19280\n"
     ]
    }
   ],
   "source": [
    "rawImages = []\n",
    "labels = []\n",
    "for ind, (img, label) in enumerate(omniglot_trainset):\n",
    "    pixels = flatten_image(np.asarray(img))\n",
    "    \n",
    "    rawImages.append(pixels)\n",
    "    labels.append(label)\n",
    "    \n",
    "    if ind > 0 and ind % 1000 == 0:\n",
    "        print(\"[INFO] processed {}/{}\".format(ind, len(omniglot_trainset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] pixels matrix: 19.28MB\n"
     ]
    }
   ],
   "source": [
    "rawImages = np.array(rawImages)\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] pixels matrix: {:.2f}MB\".format(rawImages.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainRI, testRI, trainRL, testRL) = train_test_split(rawImages, labels, test_size=0.25, random_state=1791387)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating raw pixel accuracy...\n",
      "[INFO] raw pixel accuracy: 11.04%\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating raw pixel accuracy...\")\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(trainRI, trainRL)\n",
    "acc = model.score(testRI, testRL)\n",
    "print(\"[INFO] raw pixel accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo classification run from lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-shot classification demo with Modified Hausdorff Distance\n",
      " run 1 (error 45.0%)\n",
      " run 2 (error 35.0%)\n",
      " run 3 (error 40.0%)\n",
      " run 4 (error 25.0%)\n",
      " run 5 (error 30.0%)\n",
      " run 6 (error 15.0%)\n",
      " run 7 (error 60.0%)\n",
      " run 8 (error 35.0%)\n",
      " run 9 (error 40.0%)\n",
      " run 10 (error 55.0%)\n",
      " run 11 (error 15.0%)\n",
      " run 12 (error 70.0%)\n",
      " run 13 (error 65.0%)\n",
      " run 14 (error 35.0%)\n",
      " run 15 (error 15.0%)\n",
      " run 16 (error 25.0%)\n",
      " run 17 (error 30.0%)\n",
      " run 18 (error 40.0%)\n",
      " run 19 (error 70.0%)\n",
      " run 20 (error 30.0%)\n",
      " average error 38.75%\n"
     ]
    }
   ],
   "source": [
    "# !cd one-shot-classification/all_runs/\n",
    "!python one-shot-classification/all_runs/demo_classification.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import SiameseTestData, SiameseTrainData\n",
    "from networks import SiameseNet\n",
    "from losses import ContrastiveLoss\n",
    "import torchvision.models as models\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = SiameseTrainData(omniglot_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-e2860582979e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m122\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3204\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3205\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3207\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5485\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pytorch/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    651\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    652\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 653\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1, img2, target = next(iter(trainset))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.asarray(img2), cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.asarray(img1), cmap='gray')\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = SiameseTestData(omniglot_evalset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for img1, img2 in testset:\n",
    "    i+=1\n",
    "    if i == 5:\n",
    "        break\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.asarray(img2), cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.asarray(img1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 105\n",
    "learning_rate = 1e3\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((input_size, input_size)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((input_size, input_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "omniglot_trainset = datasets.Omniglot(root='./omniglot_data/', download=True, background=True, transform=data_transforms['train'])\n",
    "omniglot_valset = datasets.Omniglot(root='./omniglot_data/', download=True, background=True, transform=data_transforms['val'])\n",
    "omniglot_evalset = datasets.Omniglot(root='./omniglot_data/', download=True, background=False, transform=data_transforms['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(omniglot_trainset)))\n",
    "split = int(0.15 * len(omniglot_trainset))\n",
    "train_indices = indices[:split]\n",
    "val_indices = indices[split:]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "trainset = SiameseTrainData(omniglot_trainset)\n",
    "valset = SiameseTestData(omniglot_valset)\n",
    "testset = SiameseTestData(omniglot_evalset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, sampler=train_sampler, num_workers=4, pin_memory=False)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, sampler=val_sampler, num_workers=4, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KochNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(KochNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # 1x105x105\n",
    "            nn.Conv2d(1, 64, kernel_size=10),\n",
    "            # 64x96x96\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # 64x48x48\n",
    "            nn.Conv2d(64, 128, kernel_size=7),\n",
    "            # 128x42x42\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # 128x21x21\n",
    "            nn.Conv2d(128, 128, kernel_size=4),\n",
    "            # 128x18x18\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # 128x9x9\n",
    "            nn.Conv2d(128, 256, kernel_size=4),\n",
    "            # 256x6x6\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.output = nn.Linear(4096, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.features(x1)\n",
    "        x1 = x1.view(x1.size(0), 256 * 6 * 6)\n",
    "        x1 = self.fc(x1)\n",
    "        x2 = self.features(x2)\n",
    "        x2 = x2.view(x2.size(0), 256 * 6 * 6)\n",
    "        x2 = self.fc(x2)\n",
    "        dist = torch.abs(x1 - x2)\n",
    "        out = self.output(dist)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KochNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "T_max = epochs\n",
    "eta_min = 0.01\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max, eta_min=eta_min)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 105, 105])\n"
     ]
    }
   ],
   "source": [
    "img1, img2, targets = next(iter(trainloader))\n",
    "output = model(img1, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, device, debug=False, print_freq=200):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for batch_idx, (imgs1, imgs2, labels) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        imgs1 = imgs1.to(device)\n",
    "        imgs2 = imgs2.to(device)\n",
    "        targets.to(device)\n",
    "\n",
    "        output = model(imgs1, img2)\n",
    "\n",
    "        loss = criterion(output, targets)\n",
    "\n",
    "        losses.update(loss.item(), imgs.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if batch_idx % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(\n",
    "                      epoch, batch_idx, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses))\n",
    "        if debug:\n",
    "            break\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(trainloader, model, criterion, optimizer, 1, device, True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
