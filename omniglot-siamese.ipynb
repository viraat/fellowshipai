{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcdaHPvTl6k1"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzQyO6MXl6lB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PKzZO4aFl6lJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kel4S_AXl6lQ"
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4TO3cYOLl6nl"
   },
   "source": [
    "## Siamese networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "94_wXkcJl6nn"
   },
   "outputs": [],
   "source": [
    "from dataloader import SiameseTestData_Omniglot, SiameseTrainData_Omniglot\n",
    "from networks import SiameseNet\n",
    "from losses import ContrastiveLoss\n",
    "import torchvision.models as models\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from utils import AverageMeter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uX05OgMLl6n5"
   },
   "outputs": [],
   "source": [
    "input_size = 105\n",
    "learning_rate = 1e3\n",
    "epochs = 500\n",
    "batch_size = 256\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    cuda = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSinghKil6n7"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((input_size, input_size)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((input_size, input_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8A1s3B0rl6n-"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPOnZFyVl6oA",
    "outputId": "e3567e7d-9181-4c21-e3ac-771e8ad406df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "omniglot_trainset = datasets.Omniglot(root='./omniglot_data/', download=True, background=True, transform=data_transforms['train'])\n",
    "omniglot_valset = datasets.Omniglot(root='./omniglot_data/', download=True, background=True, transform=data_transforms['val'])\n",
    "omniglot_evalset = datasets.Omniglot(root='./omniglot_data/', download=True, background=False, transform=data_transforms['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "waGVjQhvl6og"
   },
   "outputs": [],
   "source": [
    "indices = list(range(len(omniglot_trainset)))\n",
    "split = int(0.15 * len(omniglot_trainset))\n",
    "train_indices = indices[:split]\n",
    "val_indices = indices[split:]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = SiameseTrainData_Omniglot(omniglot_trainset)\n",
    "valset = SiameseTestData_Omniglot(omniglot_valset)\n",
    "testset = SiameseTestData_Omniglot(omniglot_evalset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tE0ksk1wl6oi"
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=train_sampler, num_workers=4, pin_memory=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, sampler=val_sampler, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6WGnzHbl6ol"
   },
   "outputs": [],
   "source": [
    "class KochNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(KochNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # 1x105x105\n",
    "            nn.Conv2d(1, 64, kernel_size=10),\n",
    "            # 64x96x96\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # 64x48x48\n",
    "            nn.Conv2d(64, 128, kernel_size=7),\n",
    "            # 128x42x42\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # 128x21x21\n",
    "            nn.Conv2d(128, 128, kernel_size=4),\n",
    "            # 128x18x18\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # 128x9x9\n",
    "            nn.Conv2d(128, 256, kernel_size=4),\n",
    "            # 256x6x6\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.output = nn.Linear(4096, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.features(x1)\n",
    "        x1 = x1.view(x1.size(0), 256 * 6 * 6)\n",
    "        x1 = self.fc(x1)\n",
    "        x2 = self.features(x2)\n",
    "        x2 = x2.view(x2.size(0), 256 * 6 * 6)\n",
    "        x2 = self.fc(x2)\n",
    "        \n",
    "        dist = torch.abs(x1 - x2)\n",
    "        out = self.output(dist)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KochNet()\n",
    "if cuda:\n",
    "    model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8s6fxM0Yl6on"
   },
   "outputs": [],
   "source": [
    "T_max = epochs\n",
    "eta_min = 0.01\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max, eta_min=eta_min)\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, device, debug=False, print_freq=200):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for batch_idx, (imgs1, imgs2, targets) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        imgs1 = imgs1.to(device).float()\n",
    "        imgs2 = imgs2.to(device).float()\n",
    "        targets = targets.to(device).float()\n",
    "\n",
    "        output = model(imgs1, imgs2)\n",
    "\n",
    "        loss = criterion(output, targets)\n",
    "\n",
    "        losses.update(loss.item(), imgs1.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if batch_idx % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(\n",
    "                      epoch, batch_idx, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses))\n",
    "        if debug:\n",
    "            break\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, epoch, device, print_freq=200):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for batch_idx, (imgs1, img2) in enumerate(val_loader):\n",
    "            imgs1 = imgs1.to(device).float()\n",
    "            imgs2 = imgs2.to(device).float()\n",
    "            \n",
    "            right, error = 0, 0\n",
    "            output = model(imgs1, imgs2)\n",
    "            pred = np.argmax(output.cpu().numpy())\n",
    "            if pred == 0:\n",
    "                right += 1\n",
    "            else: error += 1\n",
    "            print('*'*70)\n",
    "            print('[%d]\\tright:\\t%d\\terror:\\t%d\\tprecision:\\t%f'%(batch_id, right, error, right*1.0/(right+error)))\n",
    "            print('*'*70)\n",
    "            losses.update(loss.item(), imgs.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(\n",
    "                          i, len(val_loader), batch_time=batch_time, loss=losses))\n",
    "            if args.debug:\n",
    "                break\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19280"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d53koRxKl6oz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/12]\tTime 1.548 (1.548)\tData 0.650 (0.650)\tLoss 0.6930 (0.6930)\n",
      "Epoch: [0][10/12]\tTime 0.890 (0.948)\tData 0.000 (0.059)\tLoss 13483.6641 (43407.0135)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-8:\n",
      "Process Process-6:\n",
      "Process Process-5:\n",
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/var/fellowshipai/dataloader.py\", line 38, in __getitem__\n",
      "    img2, label2 = self.dataset[siamese_index]\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/var/fellowshipai/dataloader.py\", line 30, in __getitem__\n",
      "    siamese_index, (_, label2) = random.choice(self.imgs)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/omniglot.py\", line 67, in __getitem__\n",
      "    image = Image.open(image_path, mode='r').convert('L')\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/var/fellowshipai/dataloader.py\", line 30, in __getitem__\n",
      "    siamese_index, (_, label2) = random.choice(self.imgs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/random.py\", line 258, in choice\n",
      "    i = self._randbelow(len(seq))\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/random.py\", line 232, in _randbelow\n",
      "    k = n.bit_length()  # don't use (n-1) here because n can be 1\n",
      "  File \"/home/var/fellowshipai/dataloader.py\", line 30, in __getitem__\n",
      "    siamese_index, (_, label2) = random.choice(self.imgs)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/PIL/ImageFile.py\", line 190, in load\n",
      "    self.load_prepare()\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 609, in load_prepare\n",
      "    ImageFile.ImageFile.load_prepare(self)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/random.py\", line 258, in choice\n",
      "    i = self._randbelow(len(seq))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/PIL/ImageFile.py\", line 258, in load_prepare\n",
      "    self.im = Image.core.new(self.mode, self.size)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/random.py\", line 228, in _randbelow\n",
      "    getrandbits = self.getrandbits\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-29d808cb7042>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-eb1dcd3a5b10>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, device, debug, print_freq)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/diss/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/diss/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    571\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/diss/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   1660\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'elementwise_mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    scheduler.step()\n",
    "    train(trainloader, model, criterion, optimizer, e, device, False, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1087cb476f22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "omniglot.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
