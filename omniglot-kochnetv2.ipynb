{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcdaHPvTl6k1"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzQyO6MXl6lB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PKzZO4aFl6lJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kel4S_AXl6lQ"
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4TO3cYOLl6nl"
   },
   "source": [
    "## Siamese networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "94_wXkcJl6nn"
   },
   "outputs": [],
   "source": [
    "from dataloader import SiameseTestData_ImageFolder, SiameseTrainData_ImageFolder\n",
    "from networks import SiameseNet\n",
    "from losses import ContrastiveLoss\n",
    "import torchvision.models as models\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from utils import AverageMeter\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "- input size: the input size of the image for the model\n",
    "- learning rate: the learning rate for ADAM\n",
    "- epochs: total number of epochs to train\n",
    "- batch_size: size of the batch for the training data\n",
    "- num_workers: number of works for the dataloader\n",
    "- way: the n-way split for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uX05OgMLl6n5"
   },
   "outputs": [],
   "source": [
    "input_size = 105\n",
    "learning_rate = 0.0005\n",
    "epochs = 100\n",
    "sched_reset = 0\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "way = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = False\n",
    "pin_memory = False\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    cuda = True\n",
    "    pin_memory = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data transforms and Load Data\n",
    "- Train\n",
    "    - Grayscale: ImageFolder returns RGB images, convert this to 1-channel\n",
    "    - Resize: Resize to input_size\n",
    "    - RandomHorizontalFlip: Flip the image horizontally (maybe should not be doing this)\n",
    "    - ToTensor: Convert PIL image to tensor\n",
    "    - Normalize the images\n",
    "- Val: Same as train except for the random horizontal flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSinghKil6n7"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.Resize((input_size, input_size)),\n",
    "            transforms.RandomRotation(10),\n",
    "#             transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.Resize((input_size, input_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the datasets using the generic ImageFolder class from pytorch.  \n",
    "The train, valid, test split is done in `train_test_split.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPOnZFyVl6oA",
    "outputId": "e3567e7d-9181-4c21-e3ac-771e8ad406df"
   },
   "outputs": [],
   "source": [
    "trainset = datasets.ImageFolder('./omniglot_data/changed/train', transform=data_transforms['train'])\n",
    "valset = datasets.ImageFolder('./omniglot_data/changed/valid', transform=data_transforms['val'])\n",
    "testset =  datasets.ImageFolder('./omniglot_data/changed/test', transform=data_transforms['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ImageFolder datasets to a Siamese form, i.e. which returns 2 imgs.  \n",
    "Classes are present in `dataloader.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_siamese = SiameseTrainData_ImageFolder(trainset)\n",
    "val_siamese = SiameseTestData_ImageFolder(valset, times=int(len(valset)/way))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tE0ksk1wl6oi"
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_siamese, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "valloader = torch.utils.data.DataLoader(val_siamese, batch_size=way, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Siamese Network according to the Koch et al. paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6WGnzHbl6ol"
   },
   "outputs": [],
   "source": [
    "class KochNetv2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(KochNetv2, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # 1x105x105\n",
    "            nn.Conv2d(1, 64, kernel_size=10),\n",
    "            # 64x96x96\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # 64x48x48\n",
    "            nn.Conv2d(64, 128, kernel_size=7),\n",
    "            # 128x42x42\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # 128x21x21\n",
    "            nn.Conv2d(128, 128, kernel_size=4),\n",
    "            # 128x18x18\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # 128x9x9\n",
    "            nn.Conv2d(128, 256, kernel_size=4),\n",
    "            # 256x6x6\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(4096, 128)\n",
    "        )\n",
    "#         self.output = nn.Linear(4096, 1)\n",
    "    \n",
    "    def forward_one(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.forward_one(x1)\n",
    "        out2 = self.forward_one(x2)\n",
    "#         dist = torch.abs(out1 - out2)\n",
    "#         out = self.output(dist)\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the model and optimizer\n",
    "- Use ADAM optimizer with previously defined learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KochNetv2()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer.zero_grad()\n",
    "if cuda:\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function and (optionally) learning rate scheduler\n",
    "- Binary cross entropy loss as specified by Koch et. al\n",
    "- Cosine Annealing scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses import ContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8s6fxM0Yl6on"
   },
   "outputs": [],
   "source": [
    "if sched_reset != 0:\n",
    "    T_max = sched_reset\n",
    "else:\n",
    "    T_max = epochs\n",
    "# eta_min = 0.01 \n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max)\n",
    "criterion = ContrastiveLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to train and validate for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qi95lrtFl6ov"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, device, debug=False, print_freq=200):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for batch_idx, (imgs1, imgs2, targets) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        imgs1 = imgs1.to(device).float()\n",
    "        imgs2 = imgs2.to(device).float()\n",
    "        targets = targets.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "#         print(imgs1, imgs2)\n",
    "        out1, out2 = model(imgs1, imgs2)\n",
    "        output = F.pairwise_distance(out1, out2)\n",
    "#         print(output)\n",
    "#         print(out1)\n",
    "#         print('out2', out2)\n",
    "#         print('targets', targets)\n",
    "        loss = criterion(out1, out2, targets)\n",
    "#         print(loss)\n",
    "        losses.update(loss.item(), imgs1.size(0))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if batch_idx % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(\n",
    "                      epoch, batch_idx, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses))\n",
    "        if debug:\n",
    "            break\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, epoch, device, print_freq=100):\n",
    "    batch_time = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    correct, wrong = 0, 0\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for batch_idx, (imgs1, imgs2) in enumerate(val_loader):\n",
    "            imgs1 = imgs1.to(device).float()\n",
    "            imgs2 = imgs2.to(device).float()\n",
    "            \n",
    "            out1, out2 = model(imgs1, imgs2)\n",
    "#             print(out1.shape, out2.shape)\n",
    "            output = F.pairwise_distance(out1, out2)\n",
    "#             print(output)\n",
    "            pred = np.argmin(output.cpu().numpy())\n",
    "#             print(pred)\n",
    "            if pred == 0:\n",
    "                correct += 1\n",
    "            else: \n",
    "                wrong += 1\n",
    "           \n",
    "            acc = float(correct)/(correct+wrong)\n",
    "            accuracy.update(acc, correct+wrong)\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "#             break\n",
    "    print('Test: [{0}][{1}/{2}]\\t'\n",
    "          'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "          'Correct {correct} \\t Wrong {wrong}\\t'\n",
    "          'Accuracy {acc.val:.3f} ({acc.avg:.3f})\\t'.format(\n",
    "              epoch, batch_idx, len(val_loader), batch_time=batch_time,\n",
    "              correct=correct, wrong=wrong,\n",
    "              acc=accuracy))\n",
    "        \n",
    "    return accuracy.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "Epoch: [0][0/63]\tTime 1.754 (1.754)\tData 0.846 (0.846)\tLoss 1.6473 (1.6473)\n",
      "Epoch: [0][2/63]\tTime 0.911 (1.191)\tData 0.000 (0.282)\tLoss 0.9975 (1.2172)\n",
      "Epoch: [0][4/63]\tTime 0.909 (1.078)\tData 0.000 (0.169)\tLoss 1.1729 (1.2054)\n",
      "Epoch: [0][6/63]\tTime 0.908 (1.029)\tData 0.000 (0.121)\tLoss 1.0452 (1.1832)\n",
      "Epoch: [0][8/63]\tTime 0.907 (1.002)\tData 0.000 (0.094)\tLoss 1.1933 (1.1672)\n",
      "Epoch: [0][10/63]\tTime 0.907 (0.985)\tData 0.000 (0.077)\tLoss 1.0264 (1.1409)\n",
      "Epoch: [0][12/63]\tTime 0.906 (0.972)\tData 0.000 (0.065)\tLoss 1.0775 (1.1302)\n",
      "Epoch: [0][14/63]\tTime 0.905 (0.964)\tData 0.000 (0.057)\tLoss 1.0063 (1.1150)\n",
      "Epoch: [0][16/63]\tTime 0.904 (0.957)\tData 0.000 (0.050)\tLoss 1.0226 (1.1032)\n",
      "Epoch: [0][18/63]\tTime 0.906 (0.951)\tData 0.000 (0.045)\tLoss 1.0070 (1.0928)\n",
      "Epoch: [0][20/63]\tTime 0.902 (0.947)\tData 0.000 (0.041)\tLoss 1.0130 (1.0850)\n",
      "Epoch: [0][22/63]\tTime 0.906 (0.943)\tData 0.000 (0.037)\tLoss 1.0088 (1.0784)\n",
      "Epoch: [0][24/63]\tTime 0.901 (0.940)\tData 0.000 (0.034)\tLoss 0.9982 (1.0724)\n",
      "Epoch: [0][26/63]\tTime 0.904 (0.937)\tData 0.000 (0.032)\tLoss 0.9971 (1.0678)\n",
      "Epoch: [0][28/63]\tTime 0.904 (0.935)\tData 0.000 (0.029)\tLoss 1.0070 (1.0635)\n",
      "Epoch: [0][30/63]\tTime 0.905 (0.933)\tData 0.000 (0.028)\tLoss 1.0435 (1.0611)\n",
      "Epoch: [0][32/63]\tTime 0.907 (0.931)\tData 0.000 (0.026)\tLoss 1.0583 (1.0595)\n",
      "Epoch: [0][34/63]\tTime 0.901 (0.930)\tData 0.000 (0.024)\tLoss 1.0186 (1.0569)\n",
      "Epoch: [0][36/63]\tTime 0.902 (0.928)\tData 0.000 (0.023)\tLoss 1.0082 (1.0542)\n",
      "Epoch: [0][38/63]\tTime 0.903 (0.927)\tData 0.000 (0.022)\tLoss 1.0050 (1.0517)\n",
      "Epoch: [0][40/63]\tTime 0.906 (0.926)\tData 0.000 (0.021)\tLoss 1.0083 (1.0495)\n",
      "Epoch: [0][42/63]\tTime 0.908 (0.925)\tData 0.000 (0.020)\tLoss 1.0302 (1.0482)\n",
      "Epoch: [0][44/63]\tTime 0.901 (0.924)\tData 0.000 (0.019)\tLoss 0.9983 (1.0462)\n",
      "Epoch: [0][46/63]\tTime 0.903 (0.923)\tData 0.000 (0.018)\tLoss 0.9969 (1.0442)\n",
      "Epoch: [0][48/63]\tTime 0.906 (0.922)\tData 0.000 (0.017)\tLoss 1.0058 (1.0427)\n",
      "Epoch: [0][50/63]\tTime 0.906 (0.922)\tData 0.000 (0.017)\tLoss 1.0056 (1.0412)\n",
      "Epoch: [0][52/63]\tTime 0.900 (0.921)\tData 0.000 (0.016)\tLoss 1.0083 (1.0400)\n",
      "Epoch: [0][54/63]\tTime 0.902 (0.920)\tData 0.000 (0.016)\tLoss 1.0308 (1.0392)\n",
      "Epoch: [0][56/63]\tTime 0.905 (0.920)\tData 0.000 (0.015)\tLoss 1.0355 (1.0386)\n",
      "Epoch: [0][58/63]\tTime 0.905 (0.919)\tData 0.000 (0.015)\tLoss 1.0382 (1.0381)\n",
      "Epoch: [0][60/63]\tTime 0.906 (0.919)\tData 0.000 (0.014)\tLoss 0.9918 (1.0369)\n",
      "Epoch: [0][62/63]\tTime 0.674 (0.915)\tData 0.000 (0.014)\tLoss 0.9907 (1.0358)\n",
      "----------------------------------------------------------------------\n",
      "Test: [0][160/161]\tTime 0.050 (0.051)\tCorrect 31 \t Wrong 130\tAccuracy 0.193 (0.208)\t\n",
      "Avg validation acc: 0.208\n",
      "----------------------------------------------------------------------\n",
      "Epoch 0/99\tTime 65.872 (65.872)\n",
      "**********************************************************************\n",
      "Epoch: [1][0/63]\tTime 1.370 (1.370)\tData 0.605 (0.605)\tLoss 1.0039 (1.0039)\n",
      "Epoch: [1][2/63]\tTime 0.899 (1.058)\tData 0.000 (0.202)\tLoss 0.9946 (0.9972)\n",
      "Epoch: [1][4/63]\tTime 0.902 (0.997)\tData 0.000 (0.121)\tLoss 1.0459 (1.0060)\n",
      "Epoch: [1][6/63]\tTime 0.902 (0.970)\tData 0.000 (0.087)\tLoss 1.0133 (1.0075)\n",
      "Epoch: [1][8/63]\tTime 0.907 (0.955)\tData 0.000 (0.067)\tLoss 1.0315 (1.0097)\n",
      "Epoch: [1][10/63]\tTime 0.908 (0.946)\tData 0.000 (0.055)\tLoss 1.0136 (1.0134)\n",
      "Epoch: [1][12/63]\tTime 0.900 (0.940)\tData 0.000 (0.047)\tLoss 1.0288 (1.0141)\n",
      "Epoch: [1][14/63]\tTime 0.904 (0.935)\tData 0.000 (0.041)\tLoss 1.0102 (1.0135)\n",
      "Epoch: [1][16/63]\tTime 0.902 (0.931)\tData 0.000 (0.036)\tLoss 1.0074 (1.0132)\n",
      "Epoch: [1][18/63]\tTime 0.909 (0.928)\tData 0.000 (0.032)\tLoss 1.0108 (1.0125)\n",
      "Epoch: [1][20/63]\tTime 0.903 (0.926)\tData 0.000 (0.029)\tLoss 1.0191 (1.0125)\n",
      "Epoch: [1][22/63]\tTime 0.903 (0.924)\tData 0.000 (0.027)\tLoss 1.0109 (1.0132)\n",
      "Epoch: [1][24/63]\tTime 0.903 (0.923)\tData 0.000 (0.024)\tLoss 1.0037 (1.0128)\n",
      "Epoch: [1][26/63]\tTime 0.906 (0.921)\tData 0.000 (0.023)\tLoss 1.0015 (1.0124)\n",
      "Epoch: [1][28/63]\tTime 0.909 (0.920)\tData 0.000 (0.021)\tLoss 1.0258 (1.0125)\n",
      "Epoch: [1][30/63]\tTime 0.903 (0.919)\tData 0.000 (0.020)\tLoss 1.0102 (1.0123)\n",
      "Epoch: [1][32/63]\tTime 0.902 (0.918)\tData 0.000 (0.019)\tLoss 1.0186 (1.0125)\n",
      "Epoch: [1][34/63]\tTime 0.901 (0.917)\tData 0.000 (0.018)\tLoss 1.0111 (1.0124)\n",
      "Epoch: [1][36/63]\tTime 0.909 (0.917)\tData 0.000 (0.017)\tLoss 1.0148 (1.0125)\n",
      "Epoch: [1][38/63]\tTime 0.899 (0.916)\tData 0.000 (0.016)\tLoss 1.0117 (1.0124)\n",
      "Epoch: [1][40/63]\tTime 0.902 (0.915)\tData 0.000 (0.015)\tLoss 1.0138 (1.0123)\n",
      "Epoch: [1][42/63]\tTime 0.903 (0.915)\tData 0.000 (0.014)\tLoss 1.0103 (1.0122)\n",
      "Epoch: [1][44/63]\tTime 0.904 (0.914)\tData 0.000 (0.014)\tLoss 1.0069 (1.0121)\n",
      "Epoch: [1][46/63]\tTime 0.909 (0.914)\tData 0.000 (0.013)\tLoss 1.0022 (1.0117)\n",
      "Epoch: [1][48/63]\tTime 0.903 (0.913)\tData 0.000 (0.013)\tLoss 1.0188 (1.0116)\n",
      "Epoch: [1][50/63]\tTime 0.900 (0.913)\tData 0.000 (0.012)\tLoss 1.0109 (1.0116)\n",
      "Epoch: [1][52/63]\tTime 0.902 (0.913)\tData 0.000 (0.012)\tLoss 1.0206 (1.0117)\n",
      "Epoch: [1][54/63]\tTime 0.909 (0.912)\tData 0.000 (0.011)\tLoss 1.0081 (1.0117)\n",
      "Epoch: [1][56/63]\tTime 0.900 (0.912)\tData 0.000 (0.011)\tLoss 1.0103 (1.0116)\n",
      "Epoch: [1][58/63]\tTime 0.904 (0.912)\tData 0.000 (0.011)\tLoss 1.0094 (1.0116)\n",
      "Epoch: [1][60/63]\tTime 0.903 (0.912)\tData 0.000 (0.010)\tLoss 1.0011 (1.0114)\n",
      "Epoch: [1][62/63]\tTime 0.673 (0.908)\tData 0.000 (0.010)\tLoss 0.9978 (1.0110)\n",
      "----------------------------------------------------------------------\n",
      "Test: [1][160/161]\tTime 0.050 (0.051)\tCorrect 33 \t Wrong 128\tAccuracy 0.205 (0.216)\t\n",
      "Avg validation acc: 0.216\n",
      "----------------------------------------------------------------------\n",
      "Epoch 1/99\tTime 65.423 (65.648)\n",
      "**********************************************************************\n",
      "Epoch: [2][0/63]\tTime 1.594 (1.594)\tData 0.828 (0.828)\tLoss 0.9950 (0.9950)\n",
      "Epoch: [2][2/63]\tTime 0.897 (1.130)\tData 0.000 (0.276)\tLoss 0.9939 (0.9942)\n",
      "Epoch: [2][4/63]\tTime 0.902 (1.039)\tData 0.000 (0.166)\tLoss 1.0467 (1.0051)\n",
      "Epoch: [2][6/63]\tTime 0.906 (1.001)\tData 0.000 (0.118)\tLoss 1.0030 (1.0058)\n",
      "Epoch: [2][8/63]\tTime 0.903 (0.979)\tData 0.000 (0.092)\tLoss 1.0250 (1.0082)\n",
      "Epoch: [2][10/63]\tTime 0.905 (0.965)\tData 0.000 (0.075)\tLoss 1.0183 (1.0089)\n",
      "Epoch: [2][12/63]\tTime 0.899 (0.956)\tData 0.000 (0.064)\tLoss 1.0150 (1.0094)\n",
      "Epoch: [2][14/63]\tTime 0.904 (0.948)\tData 0.000 (0.055)\tLoss 1.0145 (1.0098)\n",
      "Epoch: [2][16/63]\tTime 0.903 (0.943)\tData 0.000 (0.049)\tLoss 1.0158 (1.0104)\n",
      "Epoch: [2][18/63]\tTime 0.901 (0.938)\tData 0.000 (0.044)\tLoss 1.0069 (1.0101)\n",
      "Epoch: [2][20/63]\tTime 0.900 (0.935)\tData 0.000 (0.040)\tLoss 1.0159 (1.0104)\n",
      "Epoch: [2][22/63]\tTime 0.897 (0.931)\tData 0.000 (0.036)\tLoss 1.0141 (1.0107)\n",
      "Epoch: [2][24/63]\tTime 0.901 (0.929)\tData 0.000 (0.033)\tLoss 1.0064 (1.0107)\n",
      "Epoch: [2][26/63]\tTime 0.904 (0.927)\tData 0.000 (0.031)\tLoss 1.0068 (1.0103)\n",
      "Epoch: [2][28/63]\tTime 0.908 (0.926)\tData 0.000 (0.029)\tLoss 1.0234 (1.0105)\n",
      "Epoch: [2][30/63]\tTime 0.901 (0.924)\tData 0.000 (0.027)\tLoss 1.0124 (1.0106)\n",
      "Epoch: [2][32/63]\tTime 0.896 (0.923)\tData 0.000 (0.025)\tLoss 1.0200 (1.0110)\n",
      "Epoch: [2][34/63]\tTime 0.900 (0.921)\tData 0.000 (0.024)\tLoss 1.0117 (1.0111)\n",
      "Epoch: [2][36/63]\tTime 0.902 (0.920)\tData 0.000 (0.023)\tLoss 1.0120 (1.0112)\n",
      "Epoch: [2][38/63]\tTime 0.900 (0.919)\tData 0.000 (0.021)\tLoss 1.0121 (1.0112)\n",
      "Epoch: [2][40/63]\tTime 0.900 (0.918)\tData 0.000 (0.020)\tLoss 1.0122 (1.0112)\n",
      "Epoch: [2][42/63]\tTime 0.899 (0.917)\tData 0.000 (0.020)\tLoss 1.0110 (1.0113)\n",
      "Epoch: [2][44/63]\tTime 0.905 (0.917)\tData 0.000 (0.019)\tLoss 1.0071 (1.0112)\n",
      "Epoch: [2][46/63]\tTime 0.901 (0.916)\tData 0.000 (0.018)\tLoss 1.0039 (1.0109)\n",
      "Epoch: [2][48/63]\tTime 0.900 (0.915)\tData 0.000 (0.017)\tLoss 1.0191 (1.0109)\n",
      "Epoch: [2][50/63]\tTime 0.903 (0.915)\tData 0.000 (0.016)\tLoss 1.0115 (1.0108)\n",
      "Epoch: [2][52/63]\tTime 0.899 (0.914)\tData 0.000 (0.016)\tLoss 1.0129 (1.0108)\n",
      "Epoch: [2][54/63]\tTime 0.902 (0.914)\tData 0.000 (0.015)\tLoss 1.0124 (1.0109)\n",
      "Epoch: [2][56/63]\tTime 0.903 (0.913)\tData 0.000 (0.015)\tLoss 1.0134 (1.0110)\n",
      "Epoch: [2][58/63]\tTime 0.907 (0.913)\tData 0.000 (0.014)\tLoss 1.0177 (1.0111)\n",
      "Epoch: [2][60/63]\tTime 0.900 (0.913)\tData 0.000 (0.014)\tLoss 1.0059 (1.0111)\n",
      "Epoch: [2][62/63]\tTime 0.670 (0.909)\tData 0.000 (0.013)\tLoss 1.0025 (1.0107)\n",
      "----------------------------------------------------------------------\n",
      "Test: [2][160/161]\tTime 0.050 (0.051)\tCorrect 27 \t Wrong 134\tAccuracy 0.168 (0.164)\t\n",
      "Avg validation acc: 0.164\n",
      "----------------------------------------------------------------------\n",
      "Epoch 2/99\tTime 65.498 (65.598)\n",
      "**********************************************************************\n",
      "Epoch: [3][0/63]\tTime 1.607 (1.607)\tData 0.840 (0.840)\tLoss 0.9987 (0.9987)\n",
      "Epoch: [3][2/63]\tTime 0.901 (1.135)\tData 0.000 (0.280)\tLoss 0.9949 (0.9962)\n",
      "Epoch: [3][4/63]\tTime 0.899 (1.041)\tData 0.000 (0.168)\tLoss 1.0679 (1.0105)\n",
      "Epoch: [3][6/63]\tTime 0.900 (1.001)\tData 0.000 (0.120)\tLoss 1.0038 (1.0111)\n",
      "Epoch: [3][8/63]\tTime 0.901 (0.978)\tData 0.000 (0.094)\tLoss 1.0253 (1.0119)\n",
      "Epoch: [3][10/63]\tTime 0.902 (0.964)\tData 0.000 (0.077)\tLoss 1.0168 (1.0119)\n",
      "Epoch: [3][12/63]\tTime 0.902 (0.954)\tData 0.000 (0.065)\tLoss 1.0189 (1.0128)\n",
      "Epoch: [3][14/63]\tTime 0.902 (0.947)\tData 0.000 (0.056)\tLoss 1.0146 (1.0131)\n",
      "Epoch: [3][16/63]\tTime 0.898 (0.941)\tData 0.000 (0.050)\tLoss 1.0206 (1.0135)\n",
      "Epoch: [3][18/63]\tTime 0.899 (0.937)\tData 0.000 (0.044)\tLoss 1.0077 (1.0131)\n",
      "Epoch: [3][20/63]\tTime 0.904 (0.934)\tData 0.000 (0.040)\tLoss 1.0144 (1.0131)\n",
      "Epoch: [3][22/63]\tTime 0.906 (0.931)\tData 0.000 (0.037)\tLoss 1.0166 (1.0133)\n",
      "Epoch: [3][24/63]\tTime 0.899 (0.929)\tData 0.000 (0.034)\tLoss 1.0120 (1.0134)\n",
      "Epoch: [3][26/63]\tTime 0.897 (0.926)\tData 0.000 (0.031)\tLoss 1.0073 (1.0130)\n",
      "Epoch: [3][28/63]\tTime 0.897 (0.924)\tData 0.000 (0.029)\tLoss 1.0234 (1.0131)\n",
      "Epoch: [3][30/63]\tTime 0.899 (0.923)\tData 0.000 (0.027)\tLoss 1.0154 (1.0132)\n",
      "Epoch: [3][32/63]\tTime 0.902 (0.921)\tData 0.000 (0.026)\tLoss 1.0204 (1.0134)\n",
      "Epoch: [3][34/63]\tTime 0.897 (0.920)\tData 0.000 (0.024)\tLoss 1.0136 (1.0136)\n",
      "Epoch: [3][36/63]\tTime 0.901 (0.919)\tData 0.000 (0.023)\tLoss 1.0139 (1.0136)\n",
      "Epoch: [3][38/63]\tTime 0.900 (0.918)\tData 0.000 (0.022)\tLoss 1.0159 (1.0137)\n",
      "Epoch: [3][40/63]\tTime 0.899 (0.917)\tData 0.000 (0.021)\tLoss 1.0157 (1.0137)\n",
      "Epoch: [3][42/63]\tTime 0.899 (0.916)\tData 0.000 (0.020)\tLoss 1.0131 (1.0137)\n",
      "Epoch: [3][44/63]\tTime 0.905 (0.916)\tData 0.000 (0.019)\tLoss 1.0147 (1.0138)\n",
      "Epoch: [3][46/63]\tTime 0.900 (0.915)\tData 0.000 (0.018)\tLoss 1.0081 (1.0135)\n",
      "Epoch: [3][48/63]\tTime 0.903 (0.915)\tData 0.000 (0.017)\tLoss 1.0161 (1.0134)\n",
      "Epoch: [3][50/63]\tTime 0.903 (0.914)\tData 0.000 (0.017)\tLoss 1.0117 (1.0133)\n",
      "Epoch: [3][52/63]\tTime 0.901 (0.914)\tData 0.000 (0.016)\tLoss 1.0166 (1.0133)\n",
      "Epoch: [3][54/63]\tTime 0.904 (0.913)\tData 0.000 (0.016)\tLoss 1.0130 (1.0133)\n",
      "Epoch: [3][56/63]\tTime 0.898 (0.913)\tData 0.000 (0.015)\tLoss 1.0139 (1.0133)\n",
      "Epoch: [3][58/63]\tTime 0.897 (0.912)\tData 0.000 (0.014)\tLoss 1.0145 (1.0133)\n",
      "Epoch: [3][60/63]\tTime 0.898 (0.912)\tData 0.000 (0.014)\tLoss 1.0022 (1.0131)\n",
      "Epoch: [3][62/63]\tTime 0.671 (0.908)\tData 0.000 (0.014)\tLoss 0.9967 (1.0128)\n",
      "----------------------------------------------------------------------\n",
      "Test: [3][160/161]\tTime 0.050 (0.051)\tCorrect 22 \t Wrong 139\tAccuracy 0.137 (0.142)\t\n",
      "Avg validation acc: 0.142\n",
      "----------------------------------------------------------------------\n",
      "Epoch 3/99\tTime 65.462 (65.564)\n",
      "**********************************************************************\n",
      "Epoch: [4][0/63]\tTime 1.662 (1.662)\tData 0.897 (0.897)\tLoss 1.0023 (1.0023)\n",
      "Epoch: [4][2/63]\tTime 0.905 (1.156)\tData 0.000 (0.299)\tLoss 0.9984 (0.9995)\n",
      "Epoch: [4][4/63]\tTime 0.902 (1.054)\tData 0.000 (0.180)\tLoss 1.0695 (1.0130)\n",
      "Epoch: [4][6/63]\tTime 0.907 (1.012)\tData 0.000 (0.128)\tLoss 1.0111 (1.0159)\n",
      "Epoch: [4][8/63]\tTime 0.902 (0.988)\tData 0.000 (0.100)\tLoss 1.0254 (1.0157)\n",
      "Epoch: [4][10/63]\tTime 0.904 (0.973)\tData 0.000 (0.082)\tLoss 1.0103 (1.0148)\n",
      "Epoch: [4][12/63]\tTime 0.903 (0.962)\tData 0.000 (0.069)\tLoss 1.0236 (1.0156)\n",
      "Epoch: [4][14/63]\tTime 0.906 (0.954)\tData 0.000 (0.060)\tLoss 1.0161 (1.0157)\n",
      "Epoch: [4][16/63]\tTime 0.902 (0.948)\tData 0.000 (0.053)\tLoss 1.0165 (1.0157)\n",
      "Epoch: [4][18/63]\tTime 0.902 (0.943)\tData 0.000 (0.047)\tLoss 1.0121 (1.0155)\n",
      "Epoch: [4][20/63]\tTime 0.900 (0.939)\tData 0.000 (0.043)\tLoss 1.0172 (1.0154)\n",
      "Epoch: [4][22/63]\tTime 0.899 (0.936)\tData 0.000 (0.039)\tLoss 1.0149 (1.0153)\n",
      "Epoch: [4][24/63]\tTime 0.901 (0.933)\tData 0.000 (0.036)\tLoss 1.0110 (1.0152)\n",
      "Epoch: [4][26/63]\tTime 0.897 (0.930)\tData 0.000 (0.033)\tLoss 1.0062 (1.0147)\n",
      "Epoch: [4][28/63]\tTime 0.898 (0.928)\tData 0.000 (0.031)\tLoss 1.0372 (1.0152)\n",
      "Epoch: [4][30/63]\tTime 0.898 (0.926)\tData 0.000 (0.029)\tLoss 1.0131 (1.0153)\n",
      "Epoch: [4][32/63]\tTime 0.898 (0.924)\tData 0.000 (0.027)\tLoss 1.0134 (1.0152)\n",
      "Epoch: [4][34/63]\tTime 0.899 (0.923)\tData 0.000 (0.026)\tLoss 1.0171 (1.0152)\n",
      "Epoch: [4][36/63]\tTime 0.903 (0.922)\tData 0.000 (0.024)\tLoss 1.0152 (1.0152)\n",
      "Epoch: [4][38/63]\tTime 0.901 (0.921)\tData 0.000 (0.023)\tLoss 1.0149 (1.0152)\n",
      "Epoch: [4][40/63]\tTime 0.904 (0.920)\tData 0.000 (0.022)\tLoss 1.0201 (1.0153)\n",
      "Epoch: [4][42/63]\tTime 0.899 (0.919)\tData 0.000 (0.021)\tLoss 1.0165 (1.0154)\n",
      "Epoch: [4][44/63]\tTime 0.898 (0.918)\tData 0.000 (0.020)\tLoss 1.0118 (1.0153)\n",
      "Epoch: [4][46/63]\tTime 0.897 (0.917)\tData 0.000 (0.019)\tLoss 1.0058 (1.0149)\n",
      "Epoch: [4][48/63]\tTime 0.898 (0.916)\tData 0.000 (0.019)\tLoss 1.0279 (1.0149)\n",
      "Epoch: [4][50/63]\tTime 0.898 (0.916)\tData 0.000 (0.018)\tLoss 1.0140 (1.0150)\n",
      "Epoch: [4][52/63]\tTime 0.898 (0.915)\tData 0.000 (0.017)\tLoss 1.0213 (1.0152)\n",
      "Epoch: [4][54/63]\tTime 0.897 (0.914)\tData 0.000 (0.017)\tLoss 1.0118 (1.0151)\n",
      "Epoch: [4][56/63]\tTime 0.899 (0.914)\tData 0.000 (0.016)\tLoss 1.0158 (1.0151)\n",
      "Epoch: [4][58/63]\tTime 0.903 (0.913)\tData 0.000 (0.015)\tLoss 1.0147 (1.0152)\n",
      "Epoch: [4][60/63]\tTime 0.900 (0.913)\tData 0.000 (0.015)\tLoss 1.0049 (1.0151)\n",
      "Epoch: [4][62/63]\tTime 0.673 (0.909)\tData 0.000 (0.014)\tLoss 1.0001 (1.0148)\n",
      "----------------------------------------------------------------------\n",
      "Test: [4][160/161]\tTime 0.050 (0.051)\tCorrect 28 \t Wrong 133\tAccuracy 0.174 (0.200)\t\n",
      "Avg validation acc: 0.200\n",
      "----------------------------------------------------------------------\n",
      "Epoch 4/99\tTime 65.512 (65.553)\n",
      "**********************************************************************\n",
      "Epoch: [5][0/63]\tTime 1.671 (1.671)\tData 0.908 (0.908)\tLoss 1.0030 (1.0030)\n",
      "Epoch: [5][2/63]\tTime 0.898 (1.159)\tData 0.000 (0.303)\tLoss 1.0034 (1.0025)\n",
      "Epoch: [5][4/63]\tTime 0.900 (1.056)\tData 0.000 (0.182)\tLoss 1.0700 (1.0153)\n",
      "Epoch: [5][6/63]\tTime 0.898 (1.011)\tData 0.000 (0.130)\tLoss 1.0270 (1.0220)\n",
      "Epoch: [5][8/63]\tTime 0.900 (0.986)\tData 0.000 (0.101)\tLoss 1.0236 (1.0217)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-42:\n",
      "Process Process-44:\n",
      "Process Process-43:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-41:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/var/fellowshipai/dataloader.py\", line 96, in __getitem__\n",
      "    siamese_index, (_, label2) = random.choice(self.imgs)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/random.py\", line 258, in choice\n",
      "    i = self._randbelow(len(seq))\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/var/anaconda3/envs/diss/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][10/63]\tTime 0.902 (0.970)\tData 0.000 (0.083)\tLoss 1.0144 (1.0209)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d2a2fd7c056b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-fbe94287a9bc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, device, debug, print_freq)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mimgs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mimgs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_accs = []\n",
    "epoch_time = AverageMeter()\n",
    "ep_end = time.time()\n",
    "best_acc = 0.5\n",
    "for e in range(epochs):\n",
    "    scheduler.step()\n",
    "    print('*'*70)\n",
    "    train_loss = train(trainloader, model, criterion, optimizer, e, device, False, 2)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    print('-'*70)\n",
    "    val_acc = validate(valloader, model, e, device) \n",
    "    print('Avg validation acc: {:.3f}'.format(val_acc))\n",
    "    val_accs.append(val_acc)\n",
    "    print('-'*70)\n",
    "        \n",
    "    if best_acc < val_acc and e % 3 == 0:\n",
    "        best_acc = val_acc\n",
    "        model_path = os.path.join('weights', 'kochnetv2_{}.pth'.format(e))\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print('New model saved to {} with accuracy {:.3f}'.format(model_path, best_acc))\n",
    "        \n",
    "    epoch_time.update(time.time() - ep_end)\n",
    "    ep_end = time.time()\n",
    "    print('Epoch {}/{}\\t'\n",
    "          'Time {epoch_time.val:.3f} ({epoch_time.avg:.3f})'.format(e, epochs - 1, epoch_time=epoch_time))\n",
    "    \n",
    "    # restarts\n",
    "    if sched_reset != 0 and e % sched_reset == 0 and e > 0:\n",
    "        print('$'*70)\n",
    "        print('WARM RESTART')\n",
    "        sched_reset = sched_reset * 2\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        T_max = sched_reset\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "omniglot.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
